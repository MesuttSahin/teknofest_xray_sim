# Günlük Rapor

**İsim:** \[Mert Yiğitbaşı]
**Tarih:** 2025-12-15



### 1\.  Bugün Ne Yaptım?



Veri Bölme Stratejisi (Data Splitting): Veri sızıntısını (Data Leakage) önlemek amacıyla veri setini rastgele değil, Hasta Bazlı (Patient-Level) ayırma yöntemini araştırdım ve uyguladım.



Kodlama: src/data/make\_split.py scriptini oluşturdum. Bu script ile tüm veri setini %80 Train ve %20 Validation olacak şekilde ayırdım.



TEORİK GÖREVLERİN ARAŞTIRILMASI:



Soru 1: Data Leakage (Veri Sızıntısı) Nedir? Neden Hasta Bazlı Bölüyoruz?



Cevap: Tıbbi görüntülemede, aynı hastaya ait birden fazla röntgen (farklı açılardan veya zamanlardan) bulunabilir. Eğer veriyi rastgele karıştırıp bölersek (Random Split), aynı hastanın bir görüntüsü Train, diğer görüntüsü Validation setine düşebilir.



Bu durumda model, hastalığı öğrenmek yerine hastanın kemik yapısını, vücut şeklini veya üzerindeki takıları ezberler (Overfitting). Eğitimde harika sonuç verirken, hastaneye gelen yeni bir hastada (hiç görmediği birinde) çuvallar. Bunu engellemek için bölme işlemini "Patient ID" bazlı yaparak, bir hastanın tüm görüntülerini tek bir kümeye (ya hepsi Train'e ya hepsi Val'e) koyuyoruz.





Soru 2: Multi-Class vs Multi-Label Farkı Nedir?



Cevap:



Multi-Class (Örn: Kedi/Köpek): Sınıflar birbirini dışlar. Bir resim ya kedidir ya köpektir. Çıktı \[0, 1] gibidir (Toplam olasılık 1'dir).



Multi-Label (Bizim Proje): Sınıflar bağımsızdır. Bir hastada aynı anda hem "Hernia" hem "Infiltration" olabilir. Bu yüzden çıktımız \[1, 0, 1, ...] şeklindedir (Binary Vector). Her hastalık için "Var/Yok" kararı ayrı verilir.





Teorik Araştırmamın Proje Üzerinde Öğrenimi: Projenin "Multi-Class" değil "Multi-Label Classification" (Çok Etiketli Sınıflandırma) olduğunu netleştirdim. Bu nedenle Loss fonksiyonu olarak CrossEntropy yerine BCEWithLogitsLoss kullanılması gerektiğini dokümante ettim.



Versiyon Kontrolü: Oluşturulan script ve CSV dosyalarını GitHub repoma ekleyip feature/data-splitting dalı üzerinden Pull Request (PR) açtım.



### 2\.  Karşılaşılan Hatalar ve Çözümler



Sorun: GitHub Desktop, oluşturduğum data/processed klasörünü ve içindeki CSV dosyalarını görmüyordu.



Çözüm: Klasör yapısında iç içe geçme (nested folders) hatası yapıldığını fark ettim. Klasörü ana dizine taşıdım ve .gitignore dosyasını proje yöneticimizin kontrol etmesıyle CSV dosyalarının yüklenmesine izin verdik.



Risk: Train ve Validation setlerinde aynı hastanın röntgenlerinin bulunması (Patient Overlap) riski vardı.



Çözüm: Koda train\_test\_split fonksiyonunu Patient ID üzerinde uygulayarak entegre ettim ve işlemin sonunda assert komutu ile iki küme arasında kesişim olmadığını (%0 Leakage) matematiksel olarak doğruladım.



Sorun: Proje yöneticimizin SEED' i config üzerinden al uyarısını gözden kaçırarak SEED'i config' den almamışım.



Çözüm: Proje yöneticimiz bu kısmı kendi düzeltti.



### 3\.  Sonuç

data/processed/ klasörü altında train\_list.csv (24.644 hasta) ve val\_list.csv (6.161 hasta) dosyaları başarıyla oluşturuldu.



Veri seti, modelin hastayı ezberlemesini engelleyecek şekilde güvenli bir yapıya kavuşturuldu.



Tüm değişiklikler takımın incelemesi için GitHub'a pushlandı ve PR açıldı.



GitHub Desktop üzerinden Commit \& Pull Request işlemleri ve Branch açma üzerine yaşadığım sıkıntılardan sonra bilgilerimi geliştirdim.

